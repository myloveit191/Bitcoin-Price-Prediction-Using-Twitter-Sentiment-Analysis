import asyncio
from twikit import Client, TooManyRequests
import time
from datetime import datetime
import pandas as pd
import re
import html
from configparser import ConfigParser
from random import randint
import os
import json

# Cáº¥u hÃ¬nh
# Load config
config = ConfigParser()
config.read('config.ini')
username = config['X']['username']
password = config['X']['password']
email = config['X']['email']

# Read scraping configuration
scraping_section = 'Scraping'
min_tweets = config.getint(scraping_section, 'min_tweets', fallback=1000)
start_date = config.get(scraping_section, 'start_date', fallback='2025-09-01')
end_date = config.get(scraping_section, 'end_date', fallback='2025-09-10')
keywords = config.get(scraping_section, 'keywords', fallback='bitcoin')
lang = config.get(scraping_section, 'lang', fallback='en')
provided_query = config.get(scraping_section, 'query', fallback='').strip()
product = config.get(scraping_section, 'product', fallback='Top')
count_per_request = config.getint(scraping_section, 'count_per_request', fallback=20)
request_delay_seconds = config.getint(scraping_section, 'request_delay_seconds', fallback=10)
max_rate_limit_retries = config.getint(scraping_section, 'max_rate_limit_retries', fallback=5)

# Build query if not explicitly provided
if provided_query:
    QUERY = provided_query
else:
    QUERY = f"{keywords} lang:{lang} since:{start_date} until:{end_date}"

def print_rate_limit_info():
    """
    ğŸ” NGHIÃŠN Cá»¨U TWITTER RATE LIMIT ERROR 88:
    
    Error 88 = "Rate limit exceeded" 
    
    NGUYÃŠN NHÃ‚N:
    - Twitter giá»›i háº¡n 180 requests má»—i 15 phÃºt cho search API
    - Khi vÆ°á»£t quÃ¡ giá»›i háº¡n nÃ y, API tráº£ vá» error code 88
    - Cáº§n Ä‘á»£i Ä‘áº¿n khi quota reset (thÆ°á»ng 15 phÃºt)
    
    GIáº¢I PHÃP HIá»†U QUáº¢:
    1. Exponential Backoff: TÄƒng thá»i gian Ä‘á»£i theo cáº¥p sá»‘ nhÃ¢n
    2. Intelligent Rate Management: Theo dÃµi vÃ  quáº£n lÃ½ quota
    3. Graceful Error Handling: Xá»­ lÃ½ lá»—i má»™t cÃ¡ch thÃ´ng minh
    4. Retry vá»›i Sleep: Äá»£i vÃ  thá»­ láº¡i khi gáº·p rate limit
    """
    print("ğŸ” NGHIÃŠN Cá»¨U TWITTER RATE LIMIT ERROR 88:")
    print("=" * 60)
    print("Error 88 = 'Rate limit exceeded'")
    print("\nNGUYÃŠN NHÃ‚N:")
    print("- Twitter giá»›i háº¡n 180 requests má»—i 15 phÃºt cho search API")
    print("- Khi vÆ°á»£t quÃ¡ giá»›i háº¡n nÃ y, API tráº£ vá» error code 88")
    print("- Cáº§n Ä‘á»£i Ä‘áº¿n khi quota reset (thÆ°á»ng 15 phÃºt)")
    print("\nGIáº¢I PHÃP HIá»†U QUáº¢:")
    print("1. Exponential Backoff: TÄƒng thá»i gian Ä‘á»£i theo cáº¥p sá»‘ nhÃ¢n")
    print("2. Intelligent Rate Management: Theo dÃµi vÃ  quáº£n lÃ½ quota")
    print("3. Graceful Error Handling: Xá»­ lÃ½ lá»—i má»™t cÃ¡ch thÃ´ng minh")
    print("4. Retry vá»›i Sleep: Äá»£i vÃ  thá»­ láº¡i khi gáº·p rate limit")
    print("=" * 60)

def clean_tweet_text(text):
    """
    LÃ m sáº¡ch text toÃ n diá»‡n:
    - Loáº¡i bá» URLs (http, https, www)
    - Loáº¡i bá» HTML entities vÃ  symbols
    - Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t vÃ  emoji
    - Loáº¡i bá» mentions vÃ  hashtags symbols
    """
    if not text:
        return ""
    
    # Decode HTML entities
    text = html.unescape(text)
    
    # Loáº¡i bá» URLs (bao gá»“m cáº£ shortened URLs)
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r't\.co/\S+', '', text)
    
    # Loáº¡i bá» mentions vÃ  hashtag symbols (giá»¯ láº¡i text)
    text = re.sub(r'@\w+', '', text)
    text = re.sub(r'#(\w+)', r'\1', text)  # Giá»¯ láº¡i tá»«, bá» dáº¥u #
    
    # Loáº¡i bá» emoji vÃ  kÃ½ tá»± Ä‘áº·c biá»‡t
    text = re.sub(r'[^\w\s.,!?-]', '', text)
    
    # Loáº¡i bá» sá»‘ vÃ  kÃ½ tá»± Ä‘áº·c biá»‡t khÃ¡c
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # Normalize whitespace
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    return text

def handle_rate_limit_error(attempt, max_attempts=10):
    """
    Xá»­ lÃ½ rate limit error vá»›i exponential backoff
    
    Args:
        attempt: Sá»‘ láº§n thá»­ hiá»‡n táº¡i
        max_attempts: Sá»‘ láº§n thá»­ tá»‘i Ä‘a
    
    Returns:
        wait_time: Thá»i gian Ä‘á»£i (giÃ¢y)
    """
    if attempt >= max_attempts:
        raise Exception(f"ÄÃ£ thá»­ {max_attempts} láº§n nhÆ°ng váº«n gáº·p rate limit. Dá»«ng script.")
    
    # Exponential backoff: 2^attempt * 60 seconds (tá»‘i thiá»ƒu 1 phÃºt, tá»‘i Ä‘a 15 phÃºt)
    base_wait = min(60 * (2 ** attempt), 900)  # Max 15 phÃºt
    
    # ThÃªm random jitter Ä‘á»ƒ trÃ¡nh thundering herd
    jitter = randint(10, 60)
    wait_time = base_wait + jitter
    
    print(f"ğŸš¨ RATE LIMIT HIT! Attempt {attempt + 1}/{max_attempts}")
    print(f"â° Waiting {wait_time // 60}m {wait_time % 60}s before retry...")
    print(f"ğŸ’¡ Sá»­ dá»¥ng exponential backoff strategy")
    
    return wait_time

async def robust_search_tweets(client, query, max_tweets, product='Top', count_per_request=20, request_delay_seconds=10, max_rate_limit_retries=5):
    """
    TÃ¬m kiáº¿m tweets vá»›i xá»­ lÃ½ rate limit máº¡nh máº½
    """
    tweets = []
    attempts = 0
    pagination_token = None
    
    print(f"ğŸ” Báº¯t Ä‘áº§u tÃ¬m kiáº¿m tweets vá»›i query: '{query}'")
    print(f"ğŸ¯ Má»¥c tiÃªu: {max_tweets} tweets")
    
    while len(tweets) < max_tweets and attempts < max_rate_limit_retries:
        try:
            print(f"\nğŸ“¡ Äang gá»­i request... (ÄÃ£ cÃ³ {len(tweets)} tweets)")
            
            # Thá»±c hiá»‡n search
            if pagination_token:
                search_results = await client.search_tweet(
                    query, 
                    product=product,
                    count=count_per_request,
                    cursor=pagination_token
                )
            else:
                search_results = await client.search_tweet(
                    query, 
                    product=product,
                    count=count_per_request
                )
            
            # Xá»­ lÃ½ káº¿t quáº£
            batch_tweets = []
            for tweet in search_results:
                if len(tweets) + len(batch_tweets) >= max_tweets:
                    break
                    
                batch_tweets.append({
                    'id': tweet.id,
                    'text': tweet.text,
                    'user': tweet.user.screen_name,
                    'created_at': tweet.created_at,
                    'retweet_count': tweet.retweet_count,
                    'favorite_count': tweet.favorite_count,
                    'reply_count': getattr(tweet, 'reply_count', 0)
                })
            
            tweets.extend(batch_tweets)
            print(f"âœ… Thu tháº­p Ä‘Æ°á»£c {len(batch_tweets)} tweets trong batch nÃ y")
            print(f"ğŸ“Š Tá»•ng cá»™ng: {len(tweets)}/{max_tweets} tweets")
            
            # Láº¥y pagination token cho láº§n tiáº¿p theo
            if hasattr(search_results, 'next_cursor') and search_results.next_cursor:
                pagination_token = search_results.next_cursor
            else:
                print("ğŸ“„ KhÃ´ng cÃ²n trang tiáº¿p theo")
                break
            
            # Äáº·t delay nhá» giá»¯a cÃ¡c request Ä‘á»ƒ trÃ¡nh rate limit
            await asyncio.sleep(request_delay_seconds) # configured delay
            
        except TooManyRequests as e:
            attempts += 1
            print(f"\nğŸš¨ RATE LIMIT ERROR (Code 88) detected!")
            
            wait_time = handle_rate_limit_error(attempts - 1, max_rate_limit_retries)
            
            print(f"â³ Sleeping for {wait_time} seconds...")
            await asyncio.sleep(wait_time)
            
            print("ğŸ”„ Retrying after rate limit wait...")
            continue
            
        except Exception as e:
            attempts += 1
            error_str = str(e)
            
            # Check if this is a rate limit error in disguise
            if "rate limit exceeded" in error_str.lower() or "code\":88" in error_str:
                print(f"\nğŸš¨ RATE LIMIT ERROR (Code 88) detected in exception!")
                wait_time = handle_rate_limit_error(attempts - 1, max_rate_limit_retries)
                print(f"â³ Sleeping for {wait_time} seconds...")
                await asyncio.sleep(wait_time)
                print("ğŸ”„ Retrying after rate limit wait...")
                continue
            
            print(f"âŒ Unexpected error: {error_str}")
            
            if attempts < max_rate_limit_retries:
                wait_time = 30 * attempts  # Simple linear backoff for other errors
                print(f"â³ Waiting {wait_time} seconds before retry...")
                await asyncio.sleep(wait_time)
            else:
                print(f"ğŸ’¥ Max attempts reached. Stopping.")
                break
    
    return tweets

def analyze_data_quality(tweets_data, stage=""):
    """PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng dá»¯ liá»‡u"""
    if not tweets_data:
        print(f"âš ï¸  {stage}: KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch")
        return
    
    df = pd.DataFrame(tweets_data)
    
    print(f"\nğŸ“Š {stage} - PHÃ‚N TÃCH Dá»® LIá»†U:")
    print("=" * 50)
    print(f"ğŸ“ˆ Tá»•ng sá»‘ tweets: {len(df)}")
    print(f"ğŸ‘¥ Sá»‘ users unique: {df['user'].nunique()}")
    
    if 'text' in df.columns:
        text_lengths = df['text'].str.len()
        print(f"ğŸ“ Äá»™ dÃ i text - Trung bÃ¬nh: {text_lengths.mean():.1f}")
        print(f"ğŸ“ Äá»™ dÃ i text - Min: {text_lengths.min()}, Max: {text_lengths.max()}")
        
        # Hiá»ƒn thá»‹ sample tweets
        print(f"\nğŸ” Sample tweets:")
        for i, tweet in df.head(3).iterrows():
            text_preview = tweet['text'][:100] + "..." if len(tweet['text']) > 100 else tweet['text']
            print(f"  {i+1}. @{tweet['user']}: {text_preview}")

async def main():
    print_rate_limit_info()
    
    # Login
    client = Client(language='en-US')
    
    # Thá»­ load cookies trÆ°á»›c, náº¿u fail thÃ¬ login láº¡i
    login_success = False
    
    if os.path.exists('cookies.json'):
        print("\nğŸª Loading saved cookies...")
        try:
            client.load_cookies('cookies.json')
            print("âœ… Cookies loaded successfully!")
            
            # Test cookies báº±ng cÃ¡ch thá»­ má»™t request Ä‘Æ¡n giáº£n
            try:
                test_tweets = await client.search_tweet("test", count=1)
                print("âœ… Cookies are valid!")
                login_success = True
            except Exception as e:
                print(f"âŒ Cookies invalid: {str(e)}")
                print("ğŸ”„ Will attempt fresh login...")
                login_success = False
        except Exception as e:
            print(f"âŒ Failed to load cookies: {str(e)}")
            login_success = False
    
    if not login_success:
        print("\nğŸ” Performing fresh login...")
        try:
            await client.login(auth_info_1=username, auth_info_2=email, password=password)
            client.save_cookies('cookies.json')
            print("âœ… Login successful, cookies saved!")
        except Exception as e:
            print(f"âŒ Login failed: {str(e)}")
            return
    
    print(f"\nğŸ¯ Báº¯t Ä‘áº§u thu tháº­p {min_tweets} tweets vá»›i query: '{QUERY}'")
    
    # Thu tháº­p tweets vá»›i rate limit handling
    tweets_data = await robust_search_tweets(
        client,
        QUERY,
        min_tweets,
        product=product,
        count_per_request=count_per_request,
        request_delay_seconds=request_delay_seconds,
        max_rate_limit_retries=max_rate_limit_retries,
    )
    
    if not tweets_data:
        print("âŒ KhÃ´ng thu tháº­p Ä‘Æ°á»£c tweets nÃ o!")
        return
    
    # PhÃ¢n tÃ­ch dá»¯ liá»‡u trÆ°á»›c khi clean
    analyze_data_quality(tweets_data, "TRÆ¯á»šC KHI CLEAN")
    
    # Clean dá»¯ liá»‡u
    print(f"\nğŸ§¹ Báº¯t Ä‘áº§u lÃ m sáº¡ch dá»¯ liá»‡u...")
    for tweet in tweets_data:
        original_text = tweet['text']
        tweet['text'] = clean_tweet_text(original_text)
        tweet['text_length'] = len(tweet['text'])
    
    # Loáº¡i bá» tweets cÃ³ text quÃ¡ ngáº¯n sau khi clean (< 10 kÃ½ tá»±)
    tweets_data = [tweet for tweet in tweets_data if len(tweet['text']) >= 10]
    
    # PhÃ¢n tÃ­ch dá»¯ liá»‡u sau khi clean
    analyze_data_quality(tweets_data, "SAU KHI CLEAN")
    
    # So sÃ¡nh before/after
    print(f"\nğŸ”„ SO SÃNH BEFORE/AFTER CLEANING:")
    print("=" * 50)
    sample_tweet = tweets_data[0] if tweets_data else None
    if sample_tweet:
        print("ğŸ“ VÃ­ dá»¥ text sau khi clean:")
        print(f"   Length: {sample_tweet['text_length']} chars")
        print(f"   Content: {sample_tweet['text'][:200]}...")
    
    # LÆ°u vÃ o CSV
    if tweets_data:
        df = pd.DataFrame(tweets_data)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"bitcoin_tweets_cleaned_{timestamp}.csv"
        df.to_csv(filename, index=False, encoding='utf-8')
        
        print(f"\n ÄÃƒ LUU Dá»® LIá»†U:")
        print(f" File: {filename}")
        print(f" Sá»‘ tweets: {len(df)}")
        print(f" KÃ­ch thÆ°á»›c file: {os.path.getsize(filename)} bytes")
        
        print(f"\n HOÃ€N THÃ€NH! Thu tháº­p Ä‘Æ°á»£c {len(tweets_data)} tweets Bitcoin")
        print(f"âœ¨ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch vÃ  lÆ°u vÃ o {filename}")
    else:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u!")

if __name__ == "__main__":
    asyncio.run(main())






